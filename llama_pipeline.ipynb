{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwXKMBzycOxf"
   },
   "source": [
    "# Colab setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeZtHD-6E_KT"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install accelerate sentencepiece bitsandbytes huggingface-hub datasets sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVv-PH1FdKIt"
   },
   "source": [
    "# General setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "138WhfhP6m6c"
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import faiss\n",
    "import sentence_transformers\n",
    "import torch\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV8RsbrE663d"
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXsLIWOwcVIV"
   },
   "source": [
    "# LLama2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T9cWa0cnHpIf"
   },
   "outputs": [],
   "source": [
    "checkpoint = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint,torch_dtype=torch.float16,device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "76ZuOCJjcXT2"
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Es9ozr0if2oL"
   },
   "outputs": [],
   "source": [
    "hf_dset = load_dataset(\"liar\")\n",
    "\n",
    "train_df = hf_dset[\"train\"].rename_column(\"statement\", \"text\").to_pandas()\n",
    "val_df = hf_dset[\"validation\"].rename_column(\"statement\", \"text\").to_pandas()\n",
    "test_df = hf_dset[\"test\"].rename_column(\"statement\", \"text\").to_pandas()\n",
    "\n",
    "train_df[\"id\"] = train_df[\"id\"].apply(lambda x: int(x.split(\".\")[0]))\n",
    "val_df[\"id\"] = val_df[\"id\"].apply(lambda x: int(x.split(\".\")[0]))\n",
    "test_df[\"id\"] = test_df[\"id\"].apply(lambda x: int(x.split(\".\")[0]))\n",
    "\n",
    "train_df.label = train_df.label.apply(lambda x: 0 if x == 3 else 1)\n",
    "val_df.label = val_df.label.apply(lambda x: 0 if x == 3 else 1)\n",
    "test_df.label = test_df.label.apply(lambda x: 0 if x == 3 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xvck5oz-caIr"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOyVHak6cJeU"
   },
   "source": [
    "## Zero-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M2YxNieCg-VE",
    "outputId": "e156348a-9497-4a53-9af4-061459270d7b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1283/1283 [39:06<00:00,  1.83s/it]\n"
     ]
    }
   ],
   "source": [
    "valid = 0\n",
    "correct = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "system_prompt = \"\"\"\n",
    "You are an expert in fake news. You have to follow the provided instructions precisely and answer only with true or false.\n",
    "\n",
    "Here are some rules you always follow:\n",
    "\n",
    "- Give the requested answer even if you don't have enough evidence. Use your internal knowledge.\n",
    "- Generate human readable output, avoid creating output with gibberish text.\n",
    "- Generate only the requested output, don't include any other language before or after the requested output.\n",
    "- Never say thank you, that you are happy to help, that you are an AI agent, etc. Just answer directly.\n",
    "- Generate professional language typically used in business documents in North America.\n",
    "- Never generate offensive or foul language.\n",
    "\"\"\"\n",
    "\n",
    "for idx in tqdm(range(len(test_df))):\n",
    "    txt = test_df.iloc[idx][\"text\"]\n",
    "    label = test_df.iloc[idx][\"label\"]\n",
    "    prompt = f\"\"\"\n",
    "    To the best of your knowledge, you must choose if the input text is true or false, even if you don't have enough evidence.\n",
    "\n",
    "    Input text:\n",
    "    {txt}\n",
    "    Response:\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(tokenized_chat, max_new_tokens=400)\n",
    "    result = tokenizer.decode(outputs[0][tokenized_chat.shape[1]:], skip_special_tokens=True)\n",
    "    if re.match(\"(False|True)\", result.strip()) is not None:\n",
    "        valid += 1\n",
    "        pred = 1 if \"False\" in result else 0\n",
    "        if pred == label and label == 1:\n",
    "            tp += 1\n",
    "        if pred == 0 and label == 1:\n",
    "            fn += 1\n",
    "        if pred == 1 and label == 0:\n",
    "            fp += 1\n",
    "        if pred == label:\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKCL9X4Qu_-q",
    "outputId": "12a1f1dc-1a33-4f32-dff8-c4235b997bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "661/1085, Accuracy:60.92\n"
     ]
    }
   ],
   "source": [
    "print(f\"{correct}/{valid}, Accuracy:{correct*100/valid:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WiKPKzg_fe1R",
    "outputId": "d40bd8e0-5156-4369-96ab-84f56c360539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "682/1086, Accuracy:62.80\n"
     ]
    }
   ],
   "source": [
    "print(f\"{correct}/{valid}, Accuracy:{correct*100/valid:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcBOdMkgfrPR",
    "outputId": "14e477fd-bfe7-41b0-bea0-6160ee43033f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.857\n",
      "Recall: 0.657\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {tp/(tp+fp):.3f}\")\n",
    "print(f\"Recall: {tp/(tp+fn):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YtVqMxjcdya"
   },
   "source": [
    "## Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PivqBkFdj9av"
   },
   "outputs": [],
   "source": [
    "embedder = sentence_transformers.SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "sentences = train_df[\"text\"].tolist()\n",
    "embeds = embedder.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEA2rRTvl3M3"
   },
   "outputs": [],
   "source": [
    "d = embeds.shape[1]\n",
    "k = 3\n",
    "index = faiss.IndexFlatL2(d)\n",
    "index.add(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JqG11S-FiNi_"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an expert in fake news. You have to follow the provided instructions precisely and answer only with true or false.\n",
    "It is critical to answer True or False, even if there is not enough evidence. The world leaders need the precise answer.\n",
    "\n",
    "\n",
    "Here are some rules you always follow:\n",
    "\n",
    "- Give the requested answer even if you don't have enough evidence. Use your internal knowledge.\n",
    "- Generate human readable output, avoid creating output with gibberish text.\n",
    "- Generate only the requested output, don't include any other language before or after the requested output.\n",
    "- Never say thank you, that you are happy to help, that you are an AI agent, etc. Just answer directly.\n",
    "- Generate professional language typically used in business documents in North America.\n",
    "- Never generate offensive or foul language.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T3OruOK4eu6U",
    "outputId": "8ab08e1d-4dd4-4f16-dd5d-723df6755e39"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1283/1283 [26:11<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "valid = 0\n",
    "correct = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "\n",
    "for idx in tqdm(range(len(test_df))):\n",
    "    txt = test_df.iloc[idx][\"text\"]\n",
    "    label = test_df.iloc[idx][\"label\"]\n",
    "    x_query = embedder.encode([txt])\n",
    "\n",
    "    D, I = index.search(x_query, k)  # search\n",
    "    examples = []\n",
    "    I = I[0]\n",
    "    for ex_idx, elem in enumerate(I):\n",
    "      example_label = \"False\" if train_df.iloc[elem][\"label\"] != 3 else \"True\"\n",
    "      examples.append(\"\\n\".join([f\"Example {ex_idx+1}\", f\"Text: {train_df.iloc[elem]['text']}\", f\"Label: {example_label}\"]))\n",
    "    examples = \"\\n\\n\".join(examples)\n",
    "    prompt = f\"\"\"\n",
    "{examples}\n",
    "\n",
    "Following the same format above from the examples, what is the label of the following text? You must choose True or False, even if you don't have enough evidence:\n",
    "\n",
    "Text: {txt}\n",
    "Label:\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ]\n",
    "    tokenized_chat = tokenizer.apply_chat_template(messages, tokenize=True, return_tensors=\"pt\").to(\"cuda\")\n",
    "    outputs = model.generate(tokenized_chat, max_new_tokens=50)\n",
    "    result = tokenizer.decode(outputs[0][tokenized_chat.shape[1]:], skip_special_tokens=True)\n",
    "    if re.search(\"Label: ?(False|True)\", result.strip()) is not None:\n",
    "        valid += 1\n",
    "        pred = 1 if \"False\" in result else 0\n",
    "        if pred == label and label == 1:\n",
    "            tp += 1\n",
    "        if pred == 0 and label == 1:\n",
    "            fn += 1\n",
    "        if pred == 1 and label == 0:\n",
    "            fp += 1\n",
    "        if pred == label:\n",
    "            correct += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsUKgftl0U-S",
    "outputId": "6d045baf-d6ac-4c38-a6ab-68805bc14dad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322/843, Accuracy:38.20\n"
     ]
    }
   ],
   "source": [
    "print(f\"{correct}/{valid}, Accuracy:{correct*100/valid:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ISbw6OBIHlei",
    "outputId": "dedf5b7c-4fea-40be-be94-0066949c7544"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.804\n",
      "Recall: 0.318\n"
     ]
    }
   ],
   "source": [
    "print(f\"Precision: {tp/(tp+fp):.3f}\")\n",
    "print(f\"Recall: {tp/(tp+fn):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xwXKMBzycOxf",
    "sVv-PH1FdKIt",
    "_YtVqMxjcdya"
   ],
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
