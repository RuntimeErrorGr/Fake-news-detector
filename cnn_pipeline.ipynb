{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "XNG4PI1Rl3yo",
        "UG3uHetwCI93"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google colab setup\n",
        "## A Convolutional Neural Networks approach"
      ],
      "metadata": {
        "id": "7sr3YlPqX_6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "OscXD9Bl3J-g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80036e92-cb0b-405a-a7bc-b5a3d8cecbc8"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install datasets torchmetrics gradio kaggle typing-extensions"
      ],
      "metadata": {
        "id": "W3ClJB2O2gkj"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/big_data_project/* ."
      ],
      "metadata": {
        "id": "1PwTm-edwpWI"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# General setup"
      ],
      "metadata": {
        "id": "lvLUZkyrxb8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m nltk.downloader stopwords omw-1.4 wordnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrAXNFPDyQSj",
        "outputId": "19a62884-16ac-44b7-f6e1-6490c33973c1"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/lib/python3.10/runpy.py:126: RuntimeWarning: 'nltk.downloader' found in sys.modules after import of package 'nltk', but prior to execution of 'nltk.downloader'; this may result in unpredictable behaviour\n",
            "  warn(RuntimeWarning(msg))\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import sys\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchtext\n",
        "import torchtext.data\n",
        "import torch.nn as nn\n",
        "from nltk.corpus import stopwords\n",
        "from torchmetrics import Accuracy, Precision, Recall, F1Score, MetricCollection\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "sys.path.append('.')\n",
        "from data_pipeline import get_dataloaders, text_preprocess, isot_clean, load_dataset\n",
        "from models import cnn, lstm, bert\n",
        "from models.cnn import CNN, train, evaluate\n",
        "from models.lstm import LSTMNet\n",
        "from models.bert import BERTModel"
      ],
      "metadata": {
        "id": "AWkmy8duxgiQ"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_ID = \"isot\"\n",
        "MODEL = \"cnn\"\n",
        "(train_loader, val_loader, test_loader), (tokenizer, vocab) = get_dataloaders(dataset_id=DATASET_ID, model=MODEL)"
      ],
      "metadata": {
        "id": "ImEzmNbz5Tze"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN"
      ],
      "metadata": {
        "id": "0yJsDjxi37fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model_config = {\n",
        "    \"vocab_size\": len(vocab),\n",
        "    \"embedding_dim\": 100,\n",
        "    \"n_filters\": 100,\n",
        "    \"filter_sizes\": [3,4,5],\n",
        "    \"output_dim\": 1,\n",
        "    \"dropout\": 0.5,\n",
        "    \"pad_idx\": 1\n",
        "}"
      ],
      "metadata": {
        "id": "hh5c4F_HT90x"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = CNN(**cnn_model_config)"
      ],
      "metadata": {
        "id": "VliiZYp_hPus"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "Qq7iZi8bNNPn"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = cnn_model.to(device)\n",
        "optimizer = optim.Adam(cnn_model.parameters(),lr=1e-4)\n",
        "criterion = nn.BCELoss(reduction=\"none\")\n",
        "criterion = criterion.to(device)"
      ],
      "metadata": {
        "id": "_u0HGXnrWiAv"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 1 (Fake News)"
      ],
      "metadata": {
        "id": "XNG4PI1Rl3yo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 12\n",
        "\n",
        "metrics_group = MetricCollection(\n",
        "    [\n",
        "        Accuracy(task=\"binary\"),\n",
        "        Precision(task=\"binary\"),\n",
        "        Recall(task=\"binary\"),\n",
        "        F1Score(task=\"binary\")\n",
        "    ]\n",
        ").to(device)\n",
        "class_weight = torch.tensor([1.0, 1.0]).to(device)\n",
        "best_score = None\n",
        "best_state_dict = None\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "\n",
        "    train_loss, train_metrics = train(cnn_model, train_loader, optimizer, criterion, metrics_group, class_weight, device)\n",
        "    metrics_group.reset()\n",
        "    valid_loss, valid_metrics = evaluate(cnn_model, val_loader, criterion, metrics_group, class_weight, device)\n",
        "    metrics_group.reset()\n",
        "\n",
        "    valid_f1 = valid_metrics[\"BinaryF1Score\"].cpu().item()\n",
        "    if (best_score is None) or (valid_f1 > best_score):\n",
        "        best_score = valid_f1\n",
        "        best_state_dict = cnn_model.state_dict()\n",
        "\n",
        "    print(\"Train\")\n",
        "    print(f\"Loss: {train_loss:.3f}\", end=\", \")\n",
        "    print(\", \".join([f\"{k}: {v.cpu().item() * 100:.2f}\" for k, v in train_metrics.items()]))\n",
        "\n",
        "    print(\"Validation\")\n",
        "    print(f\"Loss: {valid_loss:.3f}\", end=\", \")\n",
        "    print(\", \".join([f\"{k}: {v.cpu().item() * 100:.2f}\" for k, v in valid_metrics.items()]))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMjtmDiGYK_X",
        "outputId": "3c9c4abc-c1ae-4abb-e5c7-2517b98f7d77"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Train\n",
            "Loss: 0.677, BinaryAccuracy: 60.03, BinaryPrecision: 59.72, BinaryRecall: 56.14, BinaryF1Score: 57.87\n",
            "Validation\n",
            "Loss: 0.493, BinaryAccuracy: 82.95, BinaryPrecision: 86.85, BinaryRecall: 77.80, BinaryF1Score: 82.08\n",
            "\n",
            "Epoch 1\n",
            "Train\n",
            "Loss: 0.463, BinaryAccuracy: 77.31, BinaryPrecision: 77.06, BinaryRecall: 76.32, BinaryF1Score: 76.69\n",
            "Validation\n",
            "Loss: 0.359, BinaryAccuracy: 86.14, BinaryPrecision: 81.94, BinaryRecall: 92.86, BinaryF1Score: 87.06\n",
            "\n",
            "Epoch 2\n",
            "Train\n",
            "Loss: 0.360, BinaryAccuracy: 83.44, BinaryPrecision: 83.27, BinaryRecall: 82.78, BinaryF1Score: 83.02\n",
            "Validation\n",
            "Loss: 0.302, BinaryAccuracy: 88.18, BinaryPrecision: 86.67, BinaryRecall: 90.35, BinaryF1Score: 88.47\n",
            "\n",
            "Epoch 3\n",
            "Train\n",
            "Loss: 0.305, BinaryAccuracy: 86.41, BinaryPrecision: 86.14, BinaryRecall: 86.05, BinaryF1Score: 86.10\n",
            "Validation\n",
            "Loss: 0.266, BinaryAccuracy: 89.63, BinaryPrecision: 87.85, BinaryRecall: 92.08, BinaryF1Score: 89.92\n",
            "\n",
            "Epoch 4\n",
            "Train\n",
            "Loss: 0.268, BinaryAccuracy: 88.36, BinaryPrecision: 87.90, BinaryRecall: 88.35, BinaryF1Score: 88.13\n",
            "Validation\n",
            "Loss: 0.235, BinaryAccuracy: 90.89, BinaryPrecision: 90.77, BinaryRecall: 91.12, BinaryF1Score: 90.94\n",
            "\n",
            "Epoch 5\n",
            "Train\n",
            "Loss: 0.240, BinaryAccuracy: 89.91, BinaryPrecision: 89.44, BinaryRecall: 89.99, BinaryF1Score: 89.71\n",
            "Validation\n",
            "Loss: 0.217, BinaryAccuracy: 91.76, BinaryPrecision: 92.87, BinaryRecall: 90.54, BinaryF1Score: 91.69\n",
            "\n",
            "Epoch 6\n",
            "Train\n",
            "Loss: 0.219, BinaryAccuracy: 90.95, BinaryPrecision: 90.52, BinaryRecall: 91.03, BinaryF1Score: 90.77\n",
            "Validation\n",
            "Loss: 0.201, BinaryAccuracy: 91.57, BinaryPrecision: 89.54, BinaryRecall: 94.21, BinaryF1Score: 91.82\n",
            "\n",
            "Epoch 7\n",
            "Train\n",
            "Loss: 0.203, BinaryAccuracy: 91.81, BinaryPrecision: 91.31, BinaryRecall: 92.01, BinaryF1Score: 91.66\n",
            "Validation\n",
            "Loss: 0.200, BinaryAccuracy: 92.93, BinaryPrecision: 93.89, BinaryRecall: 91.89, BinaryF1Score: 92.88\n",
            "\n",
            "Epoch 8\n",
            "Train\n",
            "Loss: 0.184, BinaryAccuracy: 92.62, BinaryPrecision: 92.30, BinaryRecall: 92.63, BinaryF1Score: 92.47\n",
            "Validation\n",
            "Loss: 0.183, BinaryAccuracy: 93.31, BinaryPrecision: 94.81, BinaryRecall: 91.70, BinaryF1Score: 93.23\n",
            "\n",
            "Epoch 9\n",
            "Train\n",
            "Loss: 0.171, BinaryAccuracy: 93.30, BinaryPrecision: 93.11, BinaryRecall: 93.20, BinaryF1Score: 93.15\n",
            "Validation\n",
            "Loss: 0.173, BinaryAccuracy: 93.60, BinaryPrecision: 95.38, BinaryRecall: 91.70, BinaryF1Score: 93.50\n",
            "\n",
            "Epoch 10\n",
            "Train\n",
            "Loss: 0.161, BinaryAccuracy: 93.71, BinaryPrecision: 93.59, BinaryRecall: 93.54, BinaryF1Score: 93.57\n",
            "Validation\n",
            "Loss: 0.165, BinaryAccuracy: 93.80, BinaryPrecision: 94.51, BinaryRecall: 93.05, BinaryF1Score: 93.77\n",
            "\n",
            "Epoch 11\n",
            "Train\n",
            "Loss: 0.147, BinaryAccuracy: 94.23, BinaryPrecision: 94.14, BinaryRecall: 94.06, BinaryF1Score: 94.10\n",
            "Validation\n",
            "Loss: 0.156, BinaryAccuracy: 93.80, BinaryPrecision: 94.16, BinaryRecall: 93.44, BinaryF1Score: 93.80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kaggle submit (Dataset 1 only-evaluation)"
      ],
      "metadata": {
        "id": "zenSgWR8rt-D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_ids = []\n",
        "submission_labels = []\n",
        "cnn_model.load_state_dict(best_state_dict)\n",
        "cnn_model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        text, _, _, ids = batch\n",
        "        text = text.to(device)\n",
        "        submission_ids.extend(ids.tolist())\n",
        "        predictions = cnn_model(text).round().int().squeeze().detach().cpu().tolist()\n",
        "        submission_labels.extend(predictions)"
      ],
      "metadata": {
        "id": "upaw07emrx4N"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test = pd.read_csv(\"./data/Dset1/test.csv\")\n",
        "for idx in df_test[\"id\"]:\n",
        "     if idx not in submission_ids:\n",
        "        submission_ids.append(idx)\n",
        "        submission_labels.append(1)"
      ],
      "metadata": {
        "id": "Rf9j2gURrz6K"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame.from_dict({\"id\": submission_ids, \"label\": submission_labels})"
      ],
      "metadata": {
        "id": "fJBXazW7r21J"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df.to_csv(\"submission.csv\",index=False)"
      ],
      "metadata": {
        "id": "tEfuwZSer5Gv"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "mJqkg8vAr5oM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 95
        },
        "outputId": "14d05f79-ae7a-442d-84d3-7cc7540d9c97"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c7fb207a-5b1c-40c4-a9c0-71bf08879df3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c7fb207a-5b1c-40c4-a9c0-71bf08879df3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"andreilabaucristea\",\"key\":\"3d2d961388a3991779d8a25e297c991b\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "kqCBzKlMr8QX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c fake-news -f submission.csv -m \"Uploaded from Google Colab\""
      ],
      "metadata": {
        "id": "RelwDePlsAh-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53c3765c-a072-4829-dd5e-92a2b13c805d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 40.6k/40.6k [00:01<00:00, 24.9kB/s]\n",
            "Successfully submitted to Fake News"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 2 (ISOT)"
      ],
      "metadata": {
        "id": "n9jpNUqvmBqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "\n",
        "metrics_group = MetricCollection(\n",
        "    [\n",
        "        Accuracy(task=\"binary\"),\n",
        "        Precision(task=\"binary\"),\n",
        "        Recall(task=\"binary\"),\n",
        "        F1Score(task=\"binary\")\n",
        "    ]\n",
        ").to(device)\n",
        "class_weight = torch.tensor([1.0, 1.0]).to(device)\n",
        "best_score = None\n",
        "best_state_dict = None\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "\n",
        "    train_loss, train_metrics = train(cnn_model, train_loader, optimizer, criterion, metrics_group, class_weight, device)\n",
        "    metrics_group.reset()\n",
        "    valid_loss, valid_metrics = evaluate(cnn_model, val_loader, criterion, metrics_group, class_weight, device)\n",
        "    metrics_group.reset()\n",
        "\n",
        "    valid_f1 = valid_metrics[\"BinaryF1Score\"].cpu().item()\n",
        "    if (best_score is None) or (valid_f1 > best_score):\n",
        "        best_score = valid_f1\n",
        "        best_state_dict = cnn_model.state_dict()\n",
        "\n",
        "    print(\"Train\")\n",
        "    print(f\"Loss: {train_loss:.3f}\", end=\", \")\n",
        "    print(\", \".join([f\"{k}: {v.cpu().item() * 100:.2f}\" for k, v in train_metrics.items()]))\n",
        "\n",
        "    print(\"Validation\")\n",
        "    print(f\"Loss: {valid_loss:.3f}\", end=\", \")\n",
        "    print(\", \".join([f\"{k}: {v.cpu().item() * 100:.2f}\" for k, v in valid_metrics.items()]))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d5xscnfmHWW",
        "outputId": "fa0381e9-be87-447a-f346-07e8e8255a78"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Train\n",
            "Loss: 0.556, BinaryAccuracy: 70.33, BinaryPrecision: 69.20, BinaryRecall: 66.08, BinaryF1Score: 67.61\n",
            "Validation\n",
            "Loss: 0.335, BinaryAccuracy: 89.71, BinaryPrecision: 93.40, BinaryRecall: 85.09, BinaryF1Score: 89.05\n",
            "\n",
            "Epoch 1\n",
            "Train\n",
            "Loss: 0.308, BinaryAccuracy: 87.37, BinaryPrecision: 86.74, BinaryRecall: 86.21, BinaryF1Score: 86.48\n",
            "Validation\n",
            "Loss: 0.222, BinaryAccuracy: 92.50, BinaryPrecision: 92.57, BinaryRecall: 92.14, BinaryF1Score: 92.35\n",
            "\n",
            "Epoch 2\n",
            "Train\n",
            "Loss: 0.228, BinaryAccuracy: 91.21, BinaryPrecision: 90.80, BinaryRecall: 90.40, BinaryF1Score: 90.60\n",
            "Validation\n",
            "Loss: 0.173, BinaryAccuracy: 94.88, BinaryPrecision: 95.43, BinaryRecall: 94.10, BinaryF1Score: 94.76\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.load_state_dict(best_state_dict)\n",
        "test_loss, test_metrics = evaluate(\n",
        "    cnn_model,\n",
        "    test_loader,\n",
        "    criterion,\n",
        "    metrics_group,\n",
        "    class_weight,\n",
        "    device\n",
        ")\n",
        "metrics_group.reset()\n",
        "\n",
        "print(\"Test\")\n",
        "print(f\"Loss: {test_loss:.3f}\", end=\", \")\n",
        "print(\", \".join([f\"{k}: {v.cpu().item() * 100:.2f}\" for k, v in test_metrics.items()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPp0mb3iB_qr",
        "outputId": "9a21991d-1ccf-4e2d-b585-88b08e4c212d"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test\n",
            "Loss: 0.165, BinaryAccuracy: 94.46, BinaryPrecision: 95.18, BinaryRecall: 93.64, BinaryF1Score: 94.40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL='cnn'\n",
        "DATASET_ID='isot'\n",
        "torch.save(\n",
        "    {\n",
        "        \"epoch\": epoch+1,\n",
        "        \"model_state_dict\": cnn_model.state_dict(),\n",
        "        \"model_config\": cnn_model_config,\n",
        "        \"optimizer_state_dict\": optimizer.state_dict()\n",
        "    },\n",
        "    f\"checkpoints/{MODEL}_{DATASET_ID}.tar\"\n",
        ")"
      ],
      "metadata": {
        "id": "Xs90Cbzzw-Dg"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset 3 (Liar)"
      ],
      "metadata": {
        "id": "UG3uHetwCI93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 2\n",
        "\n",
        "metrics_group = MetricCollection(\n",
        "    [\n",
        "        Accuracy(task=\"binary\"),\n",
        "        Precision(task=\"binary\"),\n",
        "        Recall(task=\"binary\"),\n",
        "        F1Score(task=\"binary\")\n",
        "    ]\n",
        ").to(device)\n",
        "class_weight = torch.tensor([6.25, 1.2]).to(device)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "\n",
        "    train_loss, train_metrics = train(cnn_model, train_loader, optimizer, criterion, metrics_group, class_weight, device)\n",
        "    metrics_group.reset()\n",
        "    valid_loss, valid_metrics = evaluate(cnn_model, val_loader, criterion, metrics_group, class_weight, device)\n",
        "    metrics_group.reset()\n",
        "\n",
        "    print(\"Train\")\n",
        "    print(f\"Loss: {train_loss:.3f}\", end=\", \")\n",
        "    print(\", \".join([f\"{k}: {v.cpu().item() * 100:.2f}\" for k, v in train_metrics.items()]))\n",
        "\n",
        "    print(\"Validation\")\n",
        "    print(f\"Loss: {valid_loss:.3f}\", end=\", \")\n",
        "    print(\", \".join([f\"{k}: {v.cpu().item() * 100:.2f}\" for k, v in valid_metrics.items()]))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovy-WpfBCLTY",
        "outputId": "5b976b0d-dcb7-46b6-d8cc-44f7448eea52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0\n",
            "Train\n",
            "Loss: 1.664, BinaryAccuracy: 48.15, BinaryPrecision: 83.09, BinaryRecall: 47.68, BinaryF1Score: 60.59\n",
            "Validation\n",
            "Loss: 1.330, BinaryAccuracy: 51.25, BinaryPrecision: 86.99, BinaryRecall: 51.57, BinaryF1Score: 64.75\n",
            "\n",
            "Epoch 1\n",
            "Train\n",
            "Loss: 1.404, BinaryAccuracy: 55.33, BinaryPrecision: 87.82, BinaryRecall: 54.07, BinaryF1Score: 66.93\n",
            "Validation\n",
            "Loss: 1.311, BinaryAccuracy: 57.48, BinaryPrecision: 88.81, BinaryRecall: 58.39, BinaryF1Score: 70.45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_group = MetricCollection(\n",
        "    [\n",
        "        Accuracy(task=\"binary\"),\n",
        "        Precision(task=\"binary\"),\n",
        "        Recall(task=\"binary\"),\n",
        "        F1Score(task=\"binary\")\n",
        "    ]\n",
        ").to(device)\n",
        "class_weight = torch.tensor([6.25, 1.2]).to(device)\n",
        "test_loss, test_metrics = evaluate(cnn_model, test_loader, criterion, metrics_group, class_weight, device)\n",
        "metrics_group.reset()\n",
        "\n",
        "print(\"Test\")\n",
        "print(f\"Loss: {test_loss:.3f}\", end=\", \")\n",
        "print(\", \".join([f\"{k}: {v.cpu().item() * 100:.2f}\" for k, v in test_metrics.items()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0K26aFaJJML",
        "outputId": "2d889221-000a-49d4-f835-b22f544e5183"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test\n",
            "Loss: 0.512, BinaryAccuracy: 94.23, BinaryPrecision: 96.58, BinaryRecall: 91.68, BinaryF1Score: 94.06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## UI"
      ],
      "metadata": {
        "id": "2vGzprGoiHzp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load models"
      ],
      "metadata": {
        "id": "UGSjIedeu8_t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load LSTM model\n",
        "MODEL='lstm'\n",
        "DATASET_ID='isot'\n",
        "checkpoint = torch.load(f\"checkpoints/{MODEL}_{DATASET_ID}.tar\", map_location=device)\n",
        "lstm_model = LSTMNet(**checkpoint[\"model_config\"])\n",
        "lstm_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "lstm_model.eval()\n",
        "lstm_model = lstm_model.to(device)"
      ],
      "metadata": {
        "id": "U6-flmoZulXC"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT model\n",
        "MODEL='bert'\n",
        "DATASET_ID='isot'\n",
        "(_, _, _), (bert_tokenizer, vocab) = get_dataloaders(dataset_id=DATASET_ID, model=MODEL)\n",
        "checkpoint = torch.load(f\"checkpoints/{MODEL}_{DATASET_ID}.tar\", map_location=device)\n",
        "bert_model = BERTModel(**checkpoint[\"model_config\"])\n",
        "bert_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "bert_model.eval()\n",
        "bert_model = bert_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZbnGM2sm7Te",
        "outputId": "b5586979-49b6-4c96-efbc-b1408e800bff"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CNN model\n",
        "MODEL='cnn'\n",
        "checkpoint = torch.load(f\"checkpoints/{MODEL}_{DATASET_ID}.tar\", map_location=device)\n",
        "cnn_model = CNN(**checkpoint[\"model_config\"])\n",
        "cnn_model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "cnn_model.eval()\n",
        "cnn_model = cnn_model.to(device)"
      ],
      "metadata": {
        "id": "07JSW-sLzFwT"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake_df = pd.read_csv(\"./data/Dset2/Fake.csv\")\n",
        "true_df = pd.read_csv(\"./data/Dset2/True.csv\")"
      ],
      "metadata": {
        "id": "oeA2qRQ_iOgU"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "isot_clean(fake_df[\"text\"].sample().iloc[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "_iAwNzx_iPrZ",
        "outputId": "74f5439c-e8fa-41d3-d9eb-53f0ba2f1eb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Former DHS Official Elibiary is a big supporter of the Muslim Brotherhood and was let go from his Homeland Sec post after allegations that he improperly used classified documents. He had also made statements about the eventual return of a Muslim caliphate.Remember this picture warning us all about the Muslim Brotherhood:A former Obama administration official at the Department of Homeland Security said Sunday that when it comes to the Islamic State slaughtering Egyptian Christians,  what goes around, comes around. In a tweet posted Sunday, Mohamed Elibiary, who formerly served as senior member of the DHS  Homeland Security Advisory Council, stated,  Reading ISIS s latest mag  otherizing  Egypt s Copts. Subhanallah how what goes around comes around. Coptic ldrs did same to MB Egyptians. Subhanallah  is Arabic for  Glory to Allah,  and so in this tweet, Elibiary is expressing praise to Allah for the fact that ISIS is killing Egyptian Christians as apparent retribution for Coptic leaders doing the same to members of the Muslim Brotherhood in Egypt.In early May, ISIS published issue 9 of its magazine  Rumiyah,  which is the publication Elibiary is referencing in his tweet.The first article in the new issue is titled  The Ruling on the Belligerent Christians,  and explicitly praises the recent ISIS terror attacks against Coptic Christians in Egypt, also calling for more deadly attacks against Christians and their property. Elibiary referred to this call and other contents in the article as  otherizing  in his tweet. From among these blessed deeds were the successive attacks which the soldiers of the Islamic State in Misr1 and Sinai carried out against the Christians in those lands, targeting them with killings and assassinations, and afflicting their churches with burning and explosions,  the article in Rumiyah states.  Thus, they brought upon them tremendous detriment and deepened their wounds. The last of the blessed attacks against them were the simultaneous explosions at two of their largest churches, one in northern Misr and the other in southern Misr, in the cities of Alexandria and Tanta on their holiday on the 12th of the month of Rajab in the year 1438. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "isot_clean(true_df[\"text\"].sample().iloc[0])"
      ],
      "metadata": {
        "id": "ohoDNQ7Oi-Am",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "a476b1cb-cbc6-46d3-80c6-18d32f30cd69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The U.S. Senate Armed Services Committee backed a waiver on Thursday that will allow James Mattis to serve as President-elect Donald Trump’s secretary of defense, despite having retired as a Marine General in 2013. The panel voted 24-3 to waive a law on civilian control of the U.S. military that would have barred Mattis from assuming the position for seven years after his active duty service. The “no” votes came from three Democrats: Senators Richard Blumenthal, Kirsten Gillibrand and Elizabeth Warren. The waiver must still be approved by the full Senate, the House of Representatives Armed Services Committee and the full House to allow Mattis to serve if he is confirmed to lead the Pentagon. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['True news', 'Fake news']\n",
        "def select_inference(model_name, input_str):\n",
        "    # Choose the model based on the selected radio button\n",
        "    if model_name.lower() == \"cnn\":\n",
        "        probs = cnn.inference(cnn_model, input_str, isot=True, device=device, processor=(tokenizer, vocab))\n",
        "    elif model_name.lower() == \"bert\":\n",
        "        probs = bert.inference(bert_model, input_str, isot=True, device=device, processor=(bert_tokenizer, vocab))\n",
        "    elif model_name.lower() == \"lstm\":\n",
        "        probs = lstm.inference(lstm_model, input_str, isot=True, device=device, processor=(tokenizer, vocab))\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model name\")\n",
        "\n",
        "    probs_with_labels = {}\n",
        "    for k, v in zip(labels, probs):\n",
        "        probs_with_labels[k] = float(v)\n",
        "\n",
        "    return probs_with_labels"
      ],
      "metadata": {
        "id": "Zun4dF6ckFMP"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(select_inference('lstm', fake_df[\"text\"].sample().iloc[0]))\n",
        "print(select_inference('lstm', true_df[\"text\"].sample().iloc[0]))"
      ],
      "metadata": {
        "id": "mzoW-Ku89ycF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "624ec159-e433-4a97-ee6d-aaffcc5df1bc"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'True news': 0.9985734792426229, 'Fake news': 0.0014265207573771477}\n",
            "{'True news': 0.9966191600542516, 'Fake news': 0.0033808399457484484}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(select_inference('cnn', fake_df[\"text\"].sample().iloc[0]))\n",
        "print(select_inference('cnn', true_df[\"text\"].sample().iloc[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81YIubSLoR-F",
        "outputId": "56f4925c-0fc0-4dcf-ec2d-c666048feaca"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'True news': 0.09955835342407227, 'Fake news': 0.9004416465759277}\n",
            "{'True news': 0.8765920624136925, 'Fake news': 0.12340793758630753}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(select_inference('bert', fake_df[\"text\"].sample().iloc[0]))\n",
        "print(select_inference('bert', true_df[\"text\"].sample().iloc[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrPqKDAuoUaA",
        "outputId": "36054307-db4b-4cac-f62a-fd3220201fa7"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'True news': 2.8087177270208485e-05, 'Fake news': 0.999971866607666}\n",
            "{'True news': 0.999874472618103, 'Fake news': 0.0001254865201190114}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "model_names = [\"CNN\", \"LSTM\", \"BERT\"]\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "  with gr.Tab(\"Fake News Detection\"):\n",
        "    with gr.Row():\n",
        "      with gr.Column():\n",
        "        model_list = gr.Dropdown(\n",
        "            choices = model_names,\n",
        "            value = model_names[0],\n",
        "            label=\"Training method\",\n",
        "            allow_custom_value=False,\n",
        "            info=\"Select trained model for fake news detection\"\n",
        "        )\n",
        "        in_text = gr.Textbox(label=\"Input news\", type=\"text\", lines=5, value=isot_clean(fake_df[\"text\"].sample().iloc[0]))\n",
        "        with gr.Row():\n",
        "          with gr.Column():\n",
        "            submit_btn = gr.Button(value=\"Run\", variant='primary')\n",
        "            clear_btn = gr.ClearButton(variant='secondary', components=[in_text])\n",
        "\n",
        "          ds = gr.Dataset(\n",
        "                components=[gr.Textbox(visible=False),gr.Textbox(visible=False)],\n",
        "                headers=[\"Id\",\"News class\"],\n",
        "                samples=[[\"1\",\"FAKE\"],[\"2\",\"TRUE\"]],\n",
        "                type=\"index\"\n",
        "          )\n",
        "          out_field = gr.Label(num_top_classes=2, label=\"Prediction\")\n",
        "  submit_btn.click(\n",
        "    fn=select_inference,\n",
        "    inputs=[model_list, in_text],\n",
        "    outputs=[out_field]\n",
        "  )\n",
        "  ds.click(\n",
        "    fn=lambda idx: gr.update(value = isot_clean(true_df[\"text\"].sample().iloc[0]) if idx == 1 else isot_clean(fake_df[\"text\"].sample().iloc[0])),\n",
        "    inputs=ds,\n",
        "    outputs=in_text\n",
        "  )\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "GOjWDD8OaI6j",
        "outputId": "3a75dd0c-ebd0-4580-8edd-ff5e79304fba"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://070a2bfe4c74a643b0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://070a2bfe4c74a643b0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    }
  ]
}